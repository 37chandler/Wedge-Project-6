{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Creating a Local CSV of a Sample of Owners & Associated Transaction Records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies \n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import db_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Credentials & Establish Connection\n",
    "\n",
    "gbq_proj_id = \"dow-wedge-transactions\"\n",
    "dataset_id = \"transactions\"  \n",
    "\n",
    "client = bigquery.Client(project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the schema of the tables and save it to a text file for data type investigation\n",
    "\n",
    "def save_table_schema_to_file(project_id, dataset_id, output_file):\n",
    "    tables = client.list_tables(dataset_id)\n",
    "    with open(output_file, 'w') as f:\n",
    "        for table in tables:\n",
    "            table_ref = f\"{project_id}.{dataset_id}.{table.table_id}\"\n",
    "            table_obj = client.get_table(table_ref)\n",
    "            f.write(f\"Schema for table {table.table_id}:\\n\")\n",
    "            for schema_field in table_obj.schema:\n",
    "                f.write(f\"{schema_field.name}: {schema_field.field_type}\\n\")\n",
    "            f.write(\"\\n\")  # Add some spacing between tables\n",
    "\n",
    "# Step 2: Define the output file path and call the function\n",
    "output_schema_file = r'C:\\Users\\mason\\Desktop\\Applied Data Analytics\\Assignments\\Wedge Project\\wedge_table_schema.txt'\n",
    "save_table_schema_to_file(gbq_proj_id, dataset_id, output_schema_file)\n",
    "\n",
    "output_schema_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBQ Query to sample owners and extract records (excluding inconsistent data type columns found in Schema file)\n",
    "\n",
    "sample_query = \"\"\"\n",
    "WITH sampled_owners AS (\n",
    "  SELECT card_no\n",
    "  FROM (\n",
    "    SELECT DISTINCT card_no\n",
    "    FROM `dow-wedge-transactions.transactions.transArchive_*`\n",
    "    WHERE card_no != 3\n",
    "  )\n",
    "  ORDER BY RAND()\n",
    "  LIMIT 700  -- should be approx. 280 MB total file size \n",
    ")\n",
    "\n",
    "-- Extract all records for the sampled owner (excluding columns with data type inconsistencies (altPrice, wicable, memType, staff, organic, volDiscType) found in schema file and not needed for task 3)\n",
    "SELECT\n",
    "    datetime,\n",
    "    register_no,\n",
    "    emp_no,\n",
    "    trans_no,\n",
    "    upc,\n",
    "    description,\n",
    "    trans_type,\n",
    "    trans_subtype,\n",
    "    trans_status,\n",
    "    department,\n",
    "    quantity,\n",
    "    Scale,\n",
    "    cost,\n",
    "    unitPrice,\n",
    "    total,\n",
    "    regPrice,\n",
    "    tax,\n",
    "    taxexempt,\n",
    "    foodstamp,\n",
    "    discount,\n",
    "    memDiscount,\n",
    "    discountable,\n",
    "    discounttype,\n",
    "    voided,\n",
    "    percentDiscount,\n",
    "    ItemQtty,\n",
    "    volume,\n",
    "    VolSpecial,\n",
    "    mixMatch,\n",
    "    matched,\n",
    "    numflag,\n",
    "    itemstatus,\n",
    "    tenderstatus,\n",
    "    charflag,\n",
    "    batchHeaderID,\n",
    "    local,\n",
    "    display,\n",
    "    receipt,\n",
    "    card_no,\n",
    "    store,\n",
    "    branch,\n",
    "    match_id,\n",
    "    trans_id\n",
    "FROM `dow-wedge-transactions.transactions.transArchive_*`\n",
    "WHERE card_no IN (SELECT card_no FROM sampled_owners);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the query and save the results to a local text file\n",
    "def run_query_and_save_to_txt(query, client, destination_txt):\n",
    "    # Run the query and convert the result to a DataFrame\n",
    "    df = client.query(query).to_dataframe()\n",
    "    # Save the DataFrame to a .txt file (tab-separated format)\n",
    "    df.to_csv(destination_txt, sep='\\t', index=False)\n",
    "  \n",
    "    print(f\"Query results saved to {destination_txt}\")\n",
    "\n",
    "# Specify the destination .txt file\n",
    "destination_txt = 'sampled_owner_transactions.txt'\n",
    "run_query_and_save_to_txt(sample_query, client, destination_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: Run the query and save the results to a local CSV file (If CSV preferred)\n",
    "#def run_query_and_save_to_csv(query, client, destination_csv):\n",
    "#    df = client.query(query).to_dataframe()\n",
    "#    df.to_csv(destination_csv, index=False)\n",
    "#   print(f\"Query results saved to {destination_csv}\")\n",
    "\n",
    "# Specify the destination CSV file\n",
    "#destination_csv = 'sampled_owner_transactions.csv'\n",
    "#run_query_and_save_to_csv(sample_query, client, destination_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
